{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook wrangles the 'track' column for NIPS-2017 data to match it to NIPS-2019 tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tracks from 2019 'track' column have been aggregated into 9 'main_tracks'. \n",
    "This notebooks attempts to correlate the tracks from 2017 to 2019 to converge the two.   \n",
    "- I will read in the track labels from 2019 data\n",
    "- we will split the track column by \" -- \" delimiter to extract track information for 2017\n",
    "- we will then compare the two by grouping data\n",
    "- we will reconcile tracks with minor labeling differences across 2017 and 2019 \n",
    "- the labels which can't be reconciled will be grouped under a 'Not Found/NF' main_track label for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in NIPS data\n",
    "nips = pd.read_csv(\"../data/nips.csv\")\n",
    "\n",
    "#read in 2019 data with tracks information\n",
    "nips19 = pd.read_csv(\"../data/nips_with_track_cleaned.csv\")\n",
    "nips19 = nips19[nips19['year'] == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dict to map track to main_track(canonical label)\n",
    "\n",
    "tracks19 = nips19.track_original.unique().tolist()\n",
    "\n",
    "mt19 = nips19.main_track.unique().tolist()\n",
    "\n",
    "doc = {}\n",
    "\n",
    "for t in tracks19:    \n",
    "    t = t.split(\" -- \")\n",
    "    doc[t[1]] = t[0]\n",
    "    \n",
    "for t in mt19:\n",
    "    doc[t] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset 2017 data\n",
    "\n",
    "nips17 = nips[nips['year'] == 2017].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column to record the original track info\n",
    "\n",
    "nips17['track_original'] = nips17['track']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean specific tracks column to match 2019 tracks\n",
    "\n",
    "nips17.loc[nips17['track'] == 'Data, Competitions, Implementations, and Software', 'track'] =  \"Data, Challenges, Implementations, and Software\"\n",
    "nips17.loc[nips17['track'] == 'Dialog- and/or Communication-Based Learning', 'track'] =  \"Dialog- or Communication-Based Learning\"\n",
    "nips17.loc[nips17['track'] == 'Neuroscience and cognitive science', 'track'] =  \"Neuroscience and Cognitive Science\"\n",
    "nips17.loc[nips17['track'] == 'Video, Motion and Tracking', 'track'] =  \"Tracking and Motion in Video\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass the track column through the dict to create the main_track column\n",
    "\n",
    "tracks17 =  nips17.track.tolist()\n",
    "\n",
    "mt17 = []\n",
    "\n",
    "for t in tracks17:   \n",
    "    if t in doc:\n",
    "        mt17.append(doc[t])\n",
    "    else:\n",
    "        mt17.append('NF')\n",
    "        \n",
    "nips17['main_track'] = mt17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_track\n",
       "Algorithms                                         512\n",
       "Applications                                       252\n",
       "Data, Challenges, Implementations, and Software      6\n",
       "Deep Learning                                      349\n",
       "NF                                                  53\n",
       "Neuroscience and Cognitive Science                  88\n",
       "Optimization                                       155\n",
       "Probabilistic Methods                              197\n",
       "Reinforcement Learning and Planning                116\n",
       "Theory                                             218\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nips17.groupby(\"main_track\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Auditory Perception and Modeling',\n",
       " 'Bayesian Theory',\n",
       " 'Competitions or Challenges',\n",
       " 'Competitive Analysis',\n",
       " 'Hyperparameter Selection',\n",
       " 'Large Margin Methods',\n",
       " 'Learning to Learn',\n",
       " 'Motor Control',\n",
       " 'Music Modeling and Analysis',\n",
       " 'Natural Scene Statistics',\n",
       " 'Neural Abstract Machines',\n",
       " 'None of the above',\n",
       " 'One-Shot/Low-Shot Learning Approaches',\n",
       " 'Program Induction',\n",
       " 'Source Separation',\n",
       " 'Speech Recognition',\n",
       " 'Spike Train Generation',\n",
       " 'Systems Biology',\n",
       " 'Text Analysis',\n",
       " 'Visual Features',\n",
       " 'Visualization/Expository Techniques for Deep Networks']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list of tracks that fall under 'Not Found/NF' main_track column with individual notes\n",
    "\n",
    "nips17[nips17['main_track'] == 'NF'].track.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "    \n",
    "1. 'Bayesian Theory': 'Bayesian Nonparametrics' in tracks_2019?\n",
    "2. 'Auditory Perception and Modeling': --> Audio and Speech Processing' in tracks_2019?\n",
    "3. 'Competitions or Challenges' --> no similar track\n",
    "4. 'Competitive Analysis' --> no similar track\n",
    "\n",
    "7. 'Hyperparameter Selection' --> maybe 'Model Selection and Structure Learning' in tracks_2019?\n",
    "8. 'Large Margin Methods' --> Large Scale Learning' and Large Deviations and Asymptotic Analysis' in tracks_2019\n",
    "9. 'Learning to Learn' --> many options\n",
    "10. 'Motor Control' --> no similar track\n",
    "11. 'Music Modeling and Analysis'  --> no similar track\n",
    "12. 'Natural Scene Statistics' --> no similar track\n",
    "13. 'Neural Abstract Machines' --> no similar track\n",
    "\n",
    "15. 'None of the above' --> ??\n",
    "16. 'One-Shot/Low-Shot Learning Approaches' --> Few-Shot Learning' in tracks_2019?\n",
    "17. 'Program Induction' --> Program Understanding and Generation' in tracks_2019?\n",
    "18. 'Source Separation' --> no similar track\n",
    "19. 'Speech Recognition' --> Audio and Speech Processing' in tracks_2019?\n",
    "20. 'Spike Train Generation' -->no similar track\n",
    "21. 'Systems Biology' --> no similar track\n",
    "22. 'Text Analysis' --> Natural Language Processing' in tracks_2019?\n",
    "\n",
    "24. 'Visual Features' --> many options: Tracking and Motion in Video', Visualization or Exposition Techniques for Deep Networks', Visual Scene Analysis and Interpretation', Visual Perception' in tracks_2019\n",
    "25. 'Visualization/Expository Techniques for Deep Networks' --> same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nips17.to_csv(\"../data/nips_with_track_cleaned.csv\", mode='a', index= False, header= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = nips17[['track', 'track_original', 'main_track', 'year']]\n",
    "\n",
    "document = document.drop_duplicates()\n",
    "\n",
    "document.to_csv(\"../data/nips_yearwise_trackinfo.csv\", mode='a', index= False, header= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
